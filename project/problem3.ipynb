{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "from finetune.cifar10_models import resnet18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-trained models for dissimilar data\n",
    "\n",
    "Previously, we have seen the power of pre-trained models in classification of images. In this problem, we show the utility of pre-trained models when performing tasks that are dissimilar to the one they were trained for.\n",
    "\n",
    "Run the code below to download and visualize the data. It may take a couple minutes to download the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_label_to_name = {0: \"T-shirt/top\",\n",
    "                        1: \"Trouser\",\n",
    "                        2: \"Pullover\",\n",
    "                        3: \"Dress\",\n",
    "                        4: \"Coat\",\n",
    "                        5: \"Sandal\",\n",
    "                        6: \"Shirt\",\n",
    "                        7: \"Sneaker\",\n",
    "                        8: \"Bag\",\n",
    "                        9: \"Ankle boot\"}\n",
    "\n",
    "# transforms to match mean and std of original dataset\n",
    "trfms = transforms.Compose([transforms.ToTensor(),\n",
    "                            transforms.Normalize([0.4914], [0.2470])])\n",
    "\n",
    "# download the data\n",
    "dataset = torchvision.datasets.FashionMNIST('data', transform=trfms, download=True)\n",
    "val_dataset = torchvision.datasets.FashionMNIST('data', transform=trfms, train=False, download=True)\n",
    "\n",
    "cifar10 = torchvision.datasets.CIFAR10('data', download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part a\n",
    "\n",
    "For this question, we will be working with ResNet-18 pre-trained on ImageNet. Our task will be to classify types of clothing from a dataset called Fashion-MNIST.\n",
    "\n",
    "First, let's visualize the data from both datasets. Run the following cells and then answer the questions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, data in enumerate(dataset):\n",
    "    if i > 2:\n",
    "        break\n",
    "    img, label = data\n",
    "    img = img.numpy().squeeze()\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(class_label_to_name[label])\n",
    "    plt.show()\n",
    "    \n",
    "for i, data in enumerate(cifar10):\n",
    "    if i > 2: \n",
    "        break\n",
    "    img, label = data\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What do you observe about the data?\n",
    "\n",
    "\n",
    "\n",
    "## Looking at the data, how do you think each of these models will perform and why?\n",
    "\n",
    "1. A basic CNN\n",
    "\n",
    "2. A pre-trained model with no extra training\n",
    "\n",
    "3. A pre-trained model with all but the last layer frozen\n",
    "\n",
    "4. A basic CNN using a pre-trained model for feature extraction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part b\n",
    "Now we will implement a basic CNN in order to benchmark performance on this task. Fill in the get_width function the same as you did in question 2. You may use your code from previous parts or choose a new architecture for this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes, input_width, input_height, num_channels, num_layers=2, num_filters=[10, 20], kernel_sizes=[5, 5], pool=[True, True]):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        assert len(num_filters) == num_layers, 'length of num_filters must match num_layers'\n",
    "        assert len(kernel_sizes) == num_layers, 'length of kernel_sizes must match num_layers'\n",
    "        assert len(pool) == num_layers, 'length of pool must match num_layers'\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        num_filters = [num_channels] + num_filters\n",
    "\n",
    "        self.widths = [input_width]\n",
    "        self.heights = [input_height]\n",
    "\n",
    "        layers = []\n",
    "        for layer in range(num_layers):\n",
    "            layers.append(nn.Conv2d(num_filters[layer], num_filters[layer + 1], kernel_size=kernel_sizes[layer]))\n",
    "\n",
    "            if pool[layer]:\n",
    "                layers.append(nn.MaxPool2d(kernel_size=2))\n",
    "            layers.append(nn.ReLU())\n",
    "\n",
    "            self.widths.append(self.get_width(self.widths[-1], kernel_sizes[layer], pool[layer]))\n",
    "            self.heights.append(self.get_width(self.heights[-1], kernel_sizes[layer], pool[layer]))\n",
    "        \n",
    "        self.convs = torch.nn.Sequential(*layers)\n",
    "\n",
    "        self.ff_in_dim = self.widths[-1] * self.heights[-1] * num_filters[-1]\n",
    "        self.fc1 = nn.Linear(self.ff_in_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        return self.fc2(x)\n",
    "    \n",
    "    # assume max pool with filter width 2 and stride 2\n",
    "    def get_width(self, input_width, kernel_size, pool):\n",
    "        ### TODO complete this function\n",
    "        \n",
    "        ### End TODO\n",
    "        return conv_width\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create our simple CNN just like we did in problem 2. Determine the size of our input and output (how did you do this in problem 2?) and print out the model architecture and verify this is what you expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO create the ConvNet with the correct input and output size\n",
    "\n",
    "\n",
    "# End TODO\n",
    "cnn = ConvNet(num_classes, input_width, input_height, num_channels)\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will define a training loop and train our CNN on this dataset. Fill in the code below in order to complete the training loop. You may use code from previous parts if you would like, but it is good to get practice with this since it is a fairly common pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, feature_extract=True, num_epochs=25):\n",
    "    \"\"\"Train a model and save best weights\n",
    "    \n",
    "    Adapted From:\n",
    "        https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): Model to train\n",
    "        dataloaders ([dataloader, dataloader]): Training dataloader and validation dataloader\n",
    "        criterion (function): Loss function\n",
    "        optimizer (torch.optim): Optimizer for training\n",
    "        num_epochs (int, optional): Number of epochs to train for. Defaults to 25.\n",
    "    Returns:\n",
    "        (model, validation_accuracy): Model with best weights, Array of validation loss over training\n",
    "    \"\"\"\n",
    "    since = time.time()\n",
    "    \n",
    "    params_to_update = model.parameters()\n",
    "    print(\"Params to learn:\")\n",
    "    if feature_extract:\n",
    "        params_to_update = []\n",
    "        for name,param in model.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                params_to_update.append(param)\n",
    "                print(\"\\t\",name)\n",
    "    else:\n",
    "        for name,param in model.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                print(\"\\t\",name)\n",
    "\n",
    "    # optimizer only updates parameters that are un-frozen\n",
    "    optimizer = torch.optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "    \n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train' and not feature_extract:\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    ### TODO complete training loop\n",
    "                    \n",
    "                    ### end TODO\n",
    "                    \n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                \n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history\n",
    "\n",
    "def visualize_model(model, dataloaders, num_images=6):\n",
    "    # @source https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('predicted: {}'.format(class_label_to_name[preds[j].item()]))\n",
    "                plt.imshow(inputs.data[j].numpy().transpose(1, 2, 0).squeeze().clip(0, 1), cmap='gray')\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below in order to train your cnn. This should take about ~5 minutes for 10 epochs if you're using the default architecture. Does the performance match what you were expecting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train the model\n",
    "batch_size = 32\n",
    "train_data_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                    batch_size=batch_size,\n",
    "                                    shuffle=True)\n",
    "val_data_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                    batch_size=batch_size,\n",
    "                                    shuffle=True)\n",
    "\n",
    "dataloaders = {'train':train_data_loader, \"val\": val_data_loader}\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "trained_model, val_acc = train_model(cnn, dataloaders, criterion, feature_extract=False, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize validation loss and some predictions\n",
    "plt.plot(range(len(val_acc)), val_acc)\n",
    "plt.title(\"Val Accuracy for basic CNN\")\n",
    "plt.show()\n",
    "\n",
    "visualize_model(trained_model, dataloaders, num_images=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your observations here\n",
    "How does the basic CNN perform? Was this what you expected?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part c\n",
    "Now we will use a pre-trained model with no fine-tuning. Because we will not be fine-tuning the model, we are not going to change the input or output size. This is possible because we are using a resnet18 that is pre-trained on CIFAR-10, which happens to have the same number of classes as our new dataset. \n",
    "\n",
    "Complete the code below to examine the architecture of our pre-trained model. What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resnet = resnet18(pretrained=True)\n",
    "# TODO print out resnet-18\n",
    "\n",
    "# end of TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your observations here\n",
    "How does this model compare to our previous one? Do you see any problems with the existing architecture?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cells below to see the accuracy of the pre-trained model on our data. This will take around 5 minutes. Make sure to read through the code to understand what is going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_accuracy(model, dataloaders):\n",
    "    \"\"\"Computes accuracy on train and validation set\"\"\"\n",
    "    since = time.time()\n",
    "    \n",
    "    model.eval()   # Set model to evaluate mode\n",
    "    \n",
    "    loss = {}\n",
    "    acc = {}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for phase in ['train', 'val']:\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                # forward\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                \n",
    "                # statistics\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            acc[phase] = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Inference complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print(\"Training Accuracy: \", acc['train'], \"Validation Accuracy: \", acc['val'])\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# as you may have noticed in the previous part, the pre-trained resnet takes in 3 \n",
    "# channel images and our data has only one channel, to circumvent this, we stack\n",
    "# the single channel 3 times before passing it through our model\n",
    "trfms = transforms.Compose([transforms.ToTensor(),\n",
    "                            transforms.Lambda(lambda x: x.repeat(3, 1, 1)),\n",
    "                            transforms.Normalize([0.4914, 0.4822, 0.4466], [0.2470, 0.2435, 0.2616]),\n",
    "                            ])\n",
    "\n",
    "# create datasets with transformations\n",
    "dataset = torchvision.datasets.FashionMNIST('data', transform=trfms, download=True)\n",
    "val_dataset = torchvision.datasets.FashionMNIST('data', transform=trfms, train=False, download=True)\n",
    "\n",
    "# create dataloaders for training loop\n",
    "train_data_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                    batch_size=batch_size,\n",
    "                                    shuffle=True)\n",
    "\n",
    "val_data_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                    batch_size=batch_size,\n",
    "                                    shuffle=True)\n",
    "dataloaders = {'train':train_data_loader, \"val\": val_data_loader}\n",
    "\n",
    "acc = prediction_accuracy(resnet, dataloaders)\n",
    "visualize_model(resnet, dataloaders, num_images=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your observations here\n",
    "How does this performance compare to your basic CNN? Why is this the case? Is this what you expected?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part d\n",
    "Now we will fine-tune our model on our new task by unfreezing just the last layer of our model. This part may look similar to the previous question, but is one of the most important concepts when using pre-trained models so it is good to get some practice with this.\n",
    "\n",
    "First, let's freeze all of the layers except the last layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "finetuned_resnet = resnet18(pretrained=True)\n",
    "\n",
    "# TODO freeze all layers\n",
    "\n",
    "# End TODO\n",
    "\n",
    "# TODO re-initilize the last layer\n",
    "\n",
    "# End TODO\n",
    "\n",
    "print(finetuned_resnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train our model on our new task. Run the cells below. This will take around an hour to run 10 epochs. You may use 5 epochs but you may not get as good results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train the model\n",
    "finetuned_resnet, val_acc_resnet = train_model(finetuned_resnet, dataloaders, criterion, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize validation loss and some predictions\n",
    "plt.plot(range(len(val_acc_resnet)), val_acc_resnet)\n",
    "plt.title(\"Val Accuracy for Fine-tuned Resnet-18\")\n",
    "plt.show()\n",
    "\n",
    "visualize_model(finetuned_resnet, dataloaders, num_images=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your observations here\n",
    "How does this performance compare to your basic CNN and the pre-trained model without fine-tuning? Why is this the case? Is this what you expected? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part e\n",
    "Now we will try a combination of the previous approaches by using a pre-trained model as a feature extractor and train a basic CNN using these features. This is similar in spirit to fine-tuning more (or all) layers of our pre-trained model, however this would take quite a long time and thus we opt for a quicker approach for demonstration purposes. \n",
    "\n",
    "The idea here is that the features from lower levels of our pre-trained network are more generalizable and can transfer across different tasks better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturizedConvNet(ConvNet):\n",
    "    def __init__(self, num_classes, input_width, input_height, num_channels, num_layers=2, num_filters=[10, 20], kernel_sizes=[5, 5], pool=[True, True]):\n",
    "        # instantiate ConvNet with input sizes (64, 14, 14) since this is the shape\n",
    "        # of the extracted features. the kernel sizes are smaller because of the smaller shape\n",
    "        super().__init__(num_classes, 14, 14, 64, kernel_sizes=[3, 3])\n",
    "        \n",
    "        resnet = resnet18(pretrained=True)\n",
    "        # freeze all layers in resnet\n",
    "        for params in resnet.parameters():\n",
    "            params.requires_grad = False\n",
    "        \n",
    "        # use first 5 layers as feature extractor\n",
    "        self.features = nn.Sequential(\n",
    "            *list(resnet.children())[:-5]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # obtain features from resnet before passing through convnet\n",
    "        x = self.features(x)\n",
    "        return super().forward(x)\n",
    "\n",
    "feature_extracted_cnn = FeaturizedConvNet(10, 28, 28, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to train a your model with feature extraction. This should take about 15 minutes for 10 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train the model\n",
    "trained_feature_cnn, val_acc_feature_cnn = train_model(feature_extracted_cnn, dataloaders, criterion, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize validation loss and some predictions\n",
    "plt.plot(range(len(val_acc_feature_cnn)), val_acc_feature_cnn)\n",
    "plt.title(\"Val Accuracy for CNN with ResNet features\")\n",
    "plt.show()\n",
    "\n",
    "visualize_model(trained_feature_cnn, dataloaders, num_images=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your observations here\n",
    "How does this performance compare to the previous models? Why is this the case? Is this what you expected?\n",
    "\n",
    "\n",
    "## Final Takeaways\n",
    "What are the main takeaways from this notebook? Which method achieved the highest accuracy? Why was this/How did the dataset and task impact performance? Compare and contrast this to what you have learned in problems 1 and 2. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
